{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class SWARA_MCDA:\n",
        "    def __init__(self, expert_judgments):\n",
        "        self.expert_judgments = expert_judgments\n",
        "\n",
        "    def calculate_weights(self):\n",
        "        s_values = np.array(self.expert_judgments)\n",
        "        k_values = np.zeros_like(s_values, dtype=float)\n",
        "        q_values = np.zeros_like(s_values, dtype=float)\n",
        "\n",
        "        for i in range(len(s_values)):\n",
        "            if i == 0:\n",
        "                k_values[i] = 1\n",
        "            else:\n",
        "                tradeoff = s_values[i] / s_values[i - 1] if s_values[i - 1] != 0 else 1\n",
        "                k_values[i] = 1 + s_values[i] * tradeoff\n",
        "\n",
        "        q_values[0] = 1\n",
        "        for i in range(1, len(k_values)):\n",
        "            q_values[i] = q_values[i - 1] * k_values[i]\n",
        "\n",
        "        #Weights normalized to make sure they add up to 1\n",
        "        weights = 1 / q_values\n",
        "        w_norm = weights / weights.sum()\n",
        "        return w_norm"
      ],
      "metadata": {
        "id": "iyJ9_0DWl8bW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_dcg(scores, k=None):\n",
        "    scores = np.array(scores[:k]) if k else np.array(scores)\n",
        "    return np.sum((2 ** scores - 1) / np.log2(np.arange(2, len(scores) + 2)))\n",
        "\n",
        "def group_queries(data, query_col):\n",
        "    queries = {}\n",
        "    for idx, query_id in enumerate(data[:, query_col]):\n",
        "        queries.setdefault(query_id, []).append(idx)\n",
        "    return queries\n",
        "def compute_pairs(scores):\n",
        "    return [(i, j) for i in range(len(scores)) for j in range(len(scores)) if scores[i] > scores[j]]\n",
        "\n",
        "def compute_ndcg(scores, k=None):\n",
        "    ideal_scores = sorted(scores, reverse=True)\n",
        "    idcg = compute_dcg(ideal_scores, k)\n",
        "    if idcg == 0:\n",
        "        return 0\n",
        "    return compute_dcg(scores, k) / idcg\n",
        "\n",
        "def compute_lambda(true_scores, pred_scores, pairs, idcg):\n",
        "    if idcg == 0:\n",
        "        return np.zeros(len(pred_scores)), np.zeros(len(pred_scores))\n",
        "\n",
        "    lambdas = np.zeros(len(pred_scores))\n",
        "    weights = np.zeros(len(pred_scores))\n",
        "\n",
        "    for i, j in pairs:\n",
        "        delta_dcg = abs(\n",
        "            (2 ** true_scores[i] - 2 ** true_scores[j]) / np.log2(j + 2)\n",
        "            - (2 ** true_scores[j] - 2 ** true_scores[i]) / np.log2(i + 2)\n",
        "        ) / idcg\n",
        "        rho = 1 / (1 + np.exp(pred_scores[i] - pred_scores[j]))\n",
        "        lambda_update = delta_dcg * rho\n",
        "        lambdas[i] += lambda_update\n",
        "        lambdas[j] -= lambda_update\n",
        "        weights[i] += rho * (1 - rho) * delta_dcg\n",
        "        weights[j] += rho * (1 - rho) * delta_dcg\n",
        "\n",
        "    return lambdas, weights\n",
        "\n",
        "class LambdaMART:\n",
        "    def __init__(self, num_trees: int = 5, max_depth: int = 10, learning_rate: float = 0.1,\n",
        "                 min_samples_split: int = 10, min_samples_leaf: int = 5, l2_reg: float = 0.01):\n",
        "        self.num_trees = num_trees\n",
        "        self.learning_rate = learning_rate\n",
        "        self.max_depth = max_depth\n",
        "        self.min_samples_split = min_samples_split\n",
        "        self.min_samples_leaf = min_samples_leaf\n",
        "        self.l2_reg = l2_reg\n",
        "        self.trees = []\n",
        "        self.fitted_scores = None\n",
        "\n",
        "    def fit(self, x: np.ndarray, y: np.ndarray):\n",
        "        queries = group_queries(x, 1)\n",
        "        pred_scores = np.zeros(len(y))\n",
        "\n",
        "        idcgs = {q: compute_dcg(sorted(y[indices], reverse=True)) for q, indices in queries.items()}\n",
        "\n",
        "        for _ in range(self.num_trees):\n",
        "            lambdas = np.zeros(len(y))\n",
        "\n",
        "            for q, indices in queries.items():\n",
        "                true_scores = y[indices]\n",
        "                pred_scores_q = pred_scores[indices]\n",
        "                pairs = compute_pairs(true_scores)\n",
        "                idcg = idcgs[q]\n",
        "\n",
        "                lambda_vals, _ = compute_lambda(true_scores, pred_scores_q, pairs, idcg)\n",
        "                lambdas[indices] += lambda_vals\n",
        "\n",
        "            tree = DecisionTreeRegressor(\n",
        "                max_depth=self.max_depth,\n",
        "                min_samples_split=self.min_samples_split,\n",
        "                min_samples_leaf=self.min_samples_leaf\n",
        "            )\n",
        "            tree.fit(x[:, 2:], lambdas)\n",
        "            self.trees.append(tree)\n",
        "\n",
        "            pred_scores += self.learning_rate * tree.predict(x[:, 2:]) - self.l2_reg * pred_scores\n",
        "        self.fitted_scores = pred_scores\n",
        "        return np.argsort(-pred_scores), pred_scores\n",
        "\n",
        "    def predict(self, x: np.ndarray):\n",
        "      # Ensure the model is fitted\n",
        "      if self.fitted_scores is None:\n",
        "        raise ValueError(\"The model has not been fitted yet. Call fit before predict.\")\n",
        "\n",
        "\n",
        "      new_scores = np.zeros(x.shape[0])\n",
        "      for tree in self.trees:\n",
        "        new_scores += self.learning_rate * tree.predict(x[:, 2:])\n",
        "\n",
        "\n",
        "      all_scores = np.concatenate([self.fitted_scores, new_scores])\n",
        "      ranked_indices = np.argsort(-all_scores)\n",
        "      rank_map = {idx: rank + 1 for rank, idx in enumerate(ranked_indices)}\n",
        "\n",
        "\n",
        "      new_input_start = len(self.fitted_scores)\n",
        "      new_ranks = [rank_map[idx] for idx in range(new_input_start, new_input_start + len(new_scores))]\n",
        "\n",
        "      return new_ranks, new_scores"
      ],
      "metadata": {
        "id": "8pQ43-BLl9fi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "def load_data():\n",
        "    df = pd.read_csv(\"data2.csv\").dropna()\n",
        "\n",
        "    df = df.sample(frac=1, random_state=42)\n",
        "\n",
        "    if 'minmax' not in df.columns:\n",
        "        raise ValueError(\"The 'minmax' column is not present in the CSV file.\")\n",
        "\n",
        "\n",
        "    minmax_values = df['minmax']\n",
        "\n",
        "    relevant_columns = ['Active Personnel', 'Aircraft Carriers', 'Available Manpower',\n",
        "                        'Defense Budget', 'Fit-for-Service', 'Labor Force', 'Oil Consumption',\n",
        "                        'Total Population', 'Total Aircraft Strength']\n",
        "\n",
        "    for col in relevant_columns:\n",
        "        if col in df.columns:\n",
        "            df[col] = df[col] * minmax_values\n",
        "\n",
        "    country_names = df['Country']\n",
        "    X = df[relevant_columns]\n",
        "\n",
        "    scaler = MinMaxScaler()\n",
        "    X_normalized = scaler.fit_transform(X)\n",
        "\n",
        "    return df, country_names, X_normalized, scaler"
      ],
      "metadata": {
        "id": "jmopXVXeMck5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import MultipleLocator, FormatStrFormatter\n",
        "\n",
        "def plot_ranking(dfY_sort, ranked_countries, relevance_scores):\n",
        "    \"\"\"\n",
        "    Plots a bar chart for ranked countries with relevance scores.\n",
        "\n",
        "    Parameters:\n",
        "        dfY_sort (pd.DataFrame): DataFrame with sorted data.\n",
        "        ranked_countries (list): List of ranked country abbreviations/names.\n",
        "        relevance_scores (list): List of relevance scores.\n",
        "    \"\"\"\n",
        "\n",
        "    sorted_indices = sorted(range(len(relevance_scores)), key=lambda k: relevance_scores[k], reverse=True)\n",
        "    ranks = ['R' + str(sorted_indices.index(i) + 1) for i in range(len(relevance_scores))]\n",
        "\n",
        "\n",
        "    figure = plt.figure(figsize=(len(ranked_countries) * 1.2, 6))\n",
        "\n",
        "\n",
        "    plt.bar(range(1, len(relevance_scores) + 1), relevance_scores, color='grey', width=0.5)\n",
        "\n",
        "    plt.xticks(range(1, len(relevance_scores) + 1), ranked_countries, fontsize=14, rotation=45, ha='right')\n",
        "\n",
        "\n",
        "    plt.xlabel('Dr≈æave svijeta', fontsize=14, labelpad=20)\n",
        "    plt.ylabel('Relevantnost', fontsize=14)\n",
        "    plt.yticks(fontsize=14)\n",
        "\n",
        "    plt.axhline(0, color='black', linewidth=1)\n",
        "\n",
        "\n",
        "    for i, (score, rank) in enumerate(zip(relevance_scores, ranks)):\n",
        "        vertical_offset = 0.0001 if score >= 0 else -0.004\n",
        "        plt.text(i + 1, score + vertical_offset, rank,\n",
        "                 size=14, ha='center', va='bottom' if score >= 0 else 'top', color='black')\n",
        "\n",
        "\n",
        "    plt.gca().yaxis.set_major_locator(MultipleLocator(0.2))\n",
        "    plt.gca().yaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
        "\n",
        "\n",
        "    plt.margins(0.05, 0.05)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "2bhYz5Dl66Nk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    data, country_names, X_normalized, scaler = load_data()\n",
        "\n",
        "    features = ['Active Personnel', 'Aircraft Carriers', 'Available Manpower',\n",
        "                'Defense Budget', 'Fit-for-Service', 'Labor Force', 'Oil Consumption',\n",
        "                'Total Population','Total Aircraft Strength']\n",
        "\n",
        "    X = data[features]\n",
        "    scaler = StandardScaler()\n",
        "    X_normalized = scaler.fit_transform(X)\n",
        "\n",
        "    # Generate expert judgments for SWARA\n",
        "    expert_judgments = np.random.dirichlet(np.ones(len(features)))\n",
        "    #expert_judgments=[0.03753326, 0.02667568, 0.10663758, 0.17123656, 0.02837184, 0.12319237, 0.06684213, 0.2574416,  0.18206899] TEST FOR WEIGHTS I HAD ALREADY COMPARISSON\n",
        "    print(f'Expert judgments: {expert_judgments}')\n",
        "    print(f'Sum of expert judgments: {np.sum(expert_judgments)}')  # Confirm sum is 1\n",
        "\n",
        "\n",
        "    swara = SWARA_MCDA(expert_judgments)\n",
        "    weights = swara.calculate_weights()\n",
        "    print('Weights', weights)\n",
        "\n",
        "\n",
        "    relevance_scores = np.dot(X_normalized, weights)\n",
        "\n",
        "\n",
        "    lambda_mart = LambdaMART()\n",
        "    ranked_indices, pred_scores=lambda_mart.fit(X_normalized, relevance_scores)\n",
        "    ranked_countries = data['Country'].iloc[ranked_indices].reset_index(drop=True)\n",
        "\n",
        "    dfY_sort = pd.DataFrame({'Rank': ranked_indices, 'Score': relevance_scores[ranked_indices]})\n",
        "\n",
        "\n",
        "    plot_ranking(dfY_sort, ranked_countries, relevance_scores)"
      ],
      "metadata": {
        "id": "M2O6drxdpIC3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "t8vUBZD7HQtC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "def load_data():\n",
        "    df = pd.read_csv(\"C:/Users/azhar/Desktop/Stl/global firepower 2022 wide.csv\").dropna()\n",
        "\n",
        "\n",
        "    df = df.sample(frac=1, random_state=42)\n",
        "\n",
        "    if 'minmax' not in df.columns:\n",
        "        raise ValueError(\"The 'minmax' column is not present in the CSV file.\")\n",
        "\n",
        "\n",
        "    minmax_values = df['minmax']\n",
        "    relevant_columns = ['Active Personnel', 'Aircraft Carriers', 'Available Manpower',\n",
        "                        'Defense Budget', 'Fit-for-Service', 'Labor Force', 'Oil Consumption',\n",
        "                        'Total Population', 'Total Aircraft Strength']\n",
        "\n",
        "    for col in relevant_columns:\n",
        "        if col in df.columns:\n",
        "            df[col] = df[col] * minmax_values\n",
        "\n",
        "\n",
        "    country_names = df['country']\n",
        "    country_continent = df['continent'].unique()\n",
        "\n",
        "    X = df[relevant_columns]\n",
        "\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_normalized = scaler.fit_transform(X)\n",
        "\n",
        "    return df, country_names, X_normalized, scaler, country_continent\n"
      ],
      "metadata": {
        "id": "OKj4b6cvMzU1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Main App\n",
        "def app():\n",
        "    # Streamlit App Title\n",
        "    st.title(\"üåç Military Ranking\")\n",
        "    st.markdown(\"Rank existing countries or add a new fake country to see how it compares!\")\n",
        "\n",
        "    # User Input for Expert Judgments\n",
        "    st.write(\"### ‚úçÔ∏è Input Expert Judgments\")\n",
        "    criteria_names = ['Active Personnel', 'Aircraft Carriers', 'Available Manpower', 'Defense Budget',\n",
        "                      'Fit-for-Service', 'Labor Force', 'Oil Consumption',  'Total Population','Total Aircraft Strength']\n",
        "    expert_judgments = []\n",
        "\n",
        "    # Create 4 columns for input fields\n",
        "    columns = st.columns(3)\n",
        "    for i, criterion in enumerate(criteria_names):\n",
        "        column = columns[i % 3]\n",
        "        value = column.number_input(f\"{criterion}:\", min_value=0.0, max_value=1.0, value=0.0, step=0.01, key=criterion)\n",
        "        expert_judgments.append(value)\n",
        "\n",
        "    # Display the sum of expert judgments\n",
        "    sum_weights = sum(expert_judgments)\n",
        "    st.write(f\"### Total of Expert Judgments: {sum_weights:.2f}\")\n",
        "\n",
        "    # Check if the sum of expert judgments equals 1 and enable ranking only if valid\n",
        "    if not np.isclose(sum_weights, 1.0):\n",
        "        st.warning(\"The total of expert judgments must equal 1. Please adjust the values.\")\n",
        "        return  # Stop further execution if sum is not 1\n",
        "\n",
        "    # Calculate Weights using SWARA\n",
        "    swara = SWARA_MCDA(expert_judgments)\n",
        "    weights = swara.calculate_weights()\n",
        "\n",
        "    # Display the SWARA weights\n",
        "    columns = st.columns(3)\n",
        "    for i, (criterion, weight) in enumerate(zip(criteria_names, weights)):\n",
        "        column = columns[i % 3]\n",
        "        column.metric(label=f\"{criterion}:\", value=f\"{weight:.2f}\")\n",
        "\n",
        "    # Load and Process Data\n",
        "    try:\n",
        "        data, country_names, X_normalized, scaler, continent = load_data()\n",
        "    except FileNotFoundError:\n",
        "        st.error(\"Data file not found. Please ensure 'global firepower 2022 wide.csv' is in the correct directory.\")\n",
        "        return\n",
        "\n",
        "\n",
        "    # Calculate relevance scores\n",
        "    relevance_scores = np.dot(X_normalized, weights)\n",
        "\n",
        "    # Train LambdaMART ranking model\n",
        "    lambda_mart = LambdaMART()\n",
        "    # Get ranked indices from LambdaMART\n",
        "    ranked_indices, pred_scores =lambda_mart.fit(X_normalized, relevance_scores)\n",
        "\n",
        "    # Display ranking results\n",
        "    st.write(\"### Ranking Results:\")\n",
        "    st.write(\"Ranking countries based on the expert judgments...\")\n",
        "\n",
        "    # Retrieve ranked country names\n",
        "    ranked_countries = data['country'].iloc[ranked_indices].reset_index(drop=True)\n",
        "\n",
        "    # Dropdown menu for country selection\n",
        "    selected_country = st.selectbox(\"Select a country:\", ranked_countries)\n",
        "\n",
        "    # Display the rank of the selected country\n",
        "    if selected_country:\n",
        "      rank = ranked_countries[ranked_countries == selected_country].index[0] + 1\n",
        "      st.write(f\"The rank of **{selected_country}** is: **{rank}**\")    # Section to Add and Rank a New Fake Country\n",
        "    st.write(\"### üè¥ Add and Rank a New Fake Country\")\n",
        "\n",
        "    # Input fields for the fake country data\n",
        "    st.write(\"Enter the data for your fake country:\")\n",
        "    fake_country_data = {}\n",
        "\n",
        "    # Create 3 columns for the input fields\n",
        "    columns = st.columns(3)\n",
        "\n",
        "    # Display 3 input fields per row\n",
        "    fake_country_data['Active Personnel'] = columns[0].number_input(\"Active Personnel\", min_value=0, step=1)\n",
        "    fake_country_data['Aircraft Carriers'] = columns[1].number_input(\"Aircraft Carriers\", min_value=0, step=1)\n",
        "    fake_country_data['Available Manpower'] = columns[2].number_input(\"Available Manpower\", min_value=0, step=1)\n",
        "\n",
        "    fake_country_data['Defense Budget'] = columns[0].number_input(\"Defense Budget (in mil USD)\", min_value=0, step=1)*1000000\n",
        "    fake_country_data['Fit-for-Service'] = columns[1].number_input(\"Fit-for-Service\", min_value=0, step=1)\n",
        "    fake_country_data['Labor Force'] = columns[2].number_input(\"Labor Force\", min_value=0, step=1)\n",
        "\n",
        "    fake_country_data['Oil Consumption'] = columns[0].number_input(\"Oil Consumption\", min_value=0, step=1)\n",
        "    fake_country_data['Total Population'] = columns[1].number_input( 'Total Population', min_value=0, step=1)\n",
        "    fake_country_data['Total Aircraft Strength'] = columns[2].number_input('Total Aircraft Strength', min_value=0, step=1)\n",
        "    fake_country_df = pd.DataFrame([fake_country_data])\n",
        "\n",
        "    # Button to add the fake country and rank it\n",
        "    if st.button(\"Rank Fake Country\"):\n",
        "\n",
        "        # Normalize the fake country data using the existing scaler\n",
        "        fake_country_normalized = scaler.transform(fake_country_df[criteria_names])\n",
        "\n",
        "        # Re-rank countries including the fake country\n",
        "        new_rank,_ = lambda_mart.predict(fake_country_normalized)\n",
        "\n",
        "        # Display ranking results including the fake country\n",
        "        st.write(\"### Updated Ranking with Fake Country:\")\n",
        "        for i, country in enumerate(new_rank, start=1):\n",
        "          st.write(f\"The rank of your **Fake Country** is: {country}\")\n",
        "\n",
        "        # Top 10 Ranked Countries\n",
        "        st.write(\"### üèÜ Top 10 Highest Ranked Countries\")\n",
        "\n",
        "        # Display the top 10 ranked countries\n",
        "        top_10_countries = ranked_countries.head(10)  # Select the top 10\n",
        "        top_10_scores = pred_scores[ranked_indices[:10]]  # Get their predicted scores\n",
        "\n",
        "        # Create a DataFrame for display\n",
        "        top_10_df = pd.DataFrame({ \"Rank\": range(1, 11),\"Country\": top_10_countries,\"Relevance score\": top_10_scores})\n",
        "\n",
        "        # Reset index and drop it\n",
        "        top_10_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "        # Display the DataFrame without an extra index\n",
        "        st.table(top_10_df.set_index(\"Rank\"))\n",
        "\n"
      ],
      "metadata": {
        "id": "uK0xvGp5Gy1S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "fy73LQfrp2s9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "  #Change from main() to app() when you want to use streamlit\n",
        "  #Use main for the MCDA comparison\n",
        "    #main()\n",
        "    app()\n"
      ],
      "metadata": {
        "id": "V5zUqID4BeW3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4u-0t3wkNK2s"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}